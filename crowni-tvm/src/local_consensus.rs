// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Crowny Local Consensus Engine
// ì‹¤ì œ ë¡œì»¬ 3ì§„ í•©ì˜ â€” OpenClaw ë“€ì–¼ ë¸Œë ˆì¸ ì—°ê²°
//   Claude  :18789
//   Gemini  :18790
//   Sonnet  :18791
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

use std::collections::HashMap;
use std::time::{SystemTime, UNIX_EPOCH, Instant};

// â”€â”€ AI ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸ â”€â”€

#[derive(Debug, Clone)]
pub struct AIEndpoint {
    pub name: String,
    pub host: String,
    pub port: u16,
    pub model_type: ModelType,
    pub status: EndpointStatus,
    pub latency_ms: u32,
    pub total_calls: u64,
    pub success_rate: f64,
}

#[derive(Debug, Clone, PartialEq)]
pub enum ModelType {
    Claude,
    Gemini,
    Sonnet,
    Custom(String),
}

impl std::fmt::Display for ModelType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Claude => write!(f, "Claude"),
            Self::Gemini => write!(f, "Gemini"),
            Self::Sonnet => write!(f, "Sonnet"),
            Self::Custom(s) => write!(f, "{}", s),
        }
    }
}

#[derive(Debug, Clone, PartialEq)]
pub enum EndpointStatus {
    Online,
    Offline,
    Busy,
    Error(String),
}

impl std::fmt::Display for EndpointStatus {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Online => write!(f, "â— Online"),
            Self::Offline => write!(f, "â—‹ Offline"),
            Self::Busy => write!(f, "â— Busy"),
            Self::Error(e) => write!(f, "âœ— Error: {}", e),
        }
    }
}

impl AIEndpoint {
    pub fn new(name: &str, host: &str, port: u16, model_type: ModelType) -> Self {
        Self {
            name: name.to_string(),
            host: host.to_string(),
            port,
            model_type,
            status: EndpointStatus::Online,
            latency_ms: 0,
            total_calls: 0,
            success_rate: 1.0,
        }
    }

    pub fn url(&self) -> String {
        format!("http://{}:{}", self.host, self.port)
    }

    pub fn api_url(&self) -> String {
        format!("http://{}:{}/v1/chat/completions", self.host, self.port)
    }
}

// â”€â”€ í•©ì˜ ìš”ì²­ â”€â”€

#[derive(Debug, Clone)]
pub struct ConsensusRequest {
    pub id: u64,
    pub prompt: String,
    pub system_prompt: String,
    pub require_trit: bool,
    pub timeout_ms: u64,
    pub min_votes: usize,
    pub created_at: u64,
}

impl ConsensusRequest {
    pub fn new(id: u64, prompt: &str) -> Self {
        Self {
            id,
            prompt: prompt.to_string(),
            system_prompt: "ë‹¹ì‹ ì€ 3ì§„ íŒë‹¨ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ë°˜ë“œì‹œ [íŒì •: P] (ê¸ì •/ìŠ¹ì¸), [íŒì •: O] (ë³´ë¥˜/ë¶ˆí™•ì‹¤), [íŒì •: T] (ë¶€ì •/ê±°ë¶€) ì¤‘ í•˜ë‚˜ë¡œ ë‹µí•˜ì„¸ìš”.".to_string(),
            require_trit: true,
            timeout_ms: 30000,
            min_votes: 2,
            created_at: now_ms(),
        }
    }
}

// â”€â”€ AI ì‘ë‹µ â”€â”€

#[derive(Debug, Clone)]
pub struct AIResponse {
    pub endpoint_name: String,
    pub model_type: ModelType,
    pub text: String,
    pub trit: i8,           // +1(P), 0(O), -1(T)
    pub confidence: f64,
    pub latency_ms: u32,
    pub success: bool,
    pub error: Option<String>,
    pub timestamp: u64,
}

impl AIResponse {
    pub fn trit_label(&self) -> &str {
        match self.trit {
            1 => "P",
            -1 => "T",
            _ => "O",
        }
    }

    pub fn trit_kr(&self) -> &str {
        match self.trit {
            1 => "ì„±ê³µ",
            -1 => "ì‹¤íŒ¨",
            _ => "ë³´ë¥˜",
        }
    }
}

impl std::fmt::Display for AIResponse {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        if self.success {
            write!(f, "[{}] {} â†’ {} ({}) {}ms",
                self.trit_label(), self.endpoint_name, self.trit_kr(),
                format!("{:.0}%", self.confidence * 100.0), self.latency_ms)
        } else {
            write!(f, "[âœ—] {} â†’ ì˜¤ë¥˜: {}", self.endpoint_name,
                self.error.as_deref().unwrap_or("unknown"))
        }
    }
}

// â”€â”€ í•©ì˜ ê²°ê³¼ â”€â”€

#[derive(Debug, Clone)]
pub struct ConsensusResult {
    pub request_id: u64,
    pub prompt: String,
    pub responses: Vec<AIResponse>,
    pub final_trit: i8,
    pub confidence: f64,
    pub unanimous: bool,
    pub ctp_header: [i8; 9],
    pub total_latency_ms: u32,
    pub timestamp: u64,
}

impl ConsensusResult {
    pub fn trit_label(&self) -> &str {
        match self.final_trit {
            1 => "P(ì„±ê³µ)",
            -1 => "T(ì‹¤íŒ¨)",
            _ => "O(ë³´ë¥˜)",
        }
    }

    pub fn ctp_string(&self) -> String {
        self.ctp_header.iter().map(|t| match t {
            1 => 'P',
            -1 => 'T',
            _ => 'O',
        }).collect()
    }
}

impl std::fmt::Display for ConsensusResult {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "í•©ì˜: {} | ì‹ ë¢°ë„: {:.0}% | ë§Œì¥ì¼ì¹˜: {} | CTP: {} | {}ms",
            self.trit_label(),
            self.confidence * 100.0,
            if self.unanimous { "âœ“" } else { "âœ—" },
            self.ctp_string(),
            self.total_latency_ms)
    }
}

// â”€â”€ Trit ë¶„ë¥˜ê¸° â”€â”€

pub fn classify_trit(text: &str) -> (i8, f64) {
    let lower = text.to_lowercase();

    // ëª…ì‹œì  íŒì • íƒœê·¸ ìš°ì„ 
    if lower.contains("[íŒì •: p]") || lower.contains("[íŒì •:p]") { return (1, 0.95); }
    if lower.contains("[íŒì •: t]") || lower.contains("[íŒì •:t]") { return (-1, 0.95); }
    if lower.contains("[íŒì •: o]") || lower.contains("[íŒì •:o]") { return (0, 0.90); }

    // í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
    let pos_words = ["approve","accept","recommend","positive","yes","agree",
        "í•©ê²©","ìŠ¹ì¸","ì¢‹","ì°¬ì„±","ê°€ëŠ¥","ì í•©","ê¸ì •","ì„±ê³µ","ì¶”ì²œ","í—ˆê°€",
        "ì§„í–‰","ì‹¤í–‰","ì°¬ì„±í•©ë‹ˆë‹¤","ì¢‹ìŠµë‹ˆë‹¤","ê¶Œì¥"];
    let neg_words = ["reject","deny","negative","no","disagree","refuse",
        "ë¶ˆí•©ê²©","ê±°ë¶€","ë¶€ì ","ë°˜ëŒ€","ë¶ˆê°€","ìœ„í—˜","ì‹¤íŒ¨","ê±°ì ˆ","ì¤‘ë‹¨",
        "í•˜ì§€ë§ˆ","ìœ„í—˜í•©ë‹ˆë‹¤","ë°˜ëŒ€í•©ë‹ˆë‹¤","ë¶ˆê°€ëŠ¥"];
    let neu_words = ["uncertain","maybe","depends","unclear",
        "ë¶ˆí™•ì‹¤","ë³´ë¥˜","ì¶”ê°€ê²€í† ","íŒë‹¨ìœ ë³´","ì •ë³´ë¶€ì¡±","ìƒí™©ì—ë”°ë¼"];

    let p_score: usize = pos_words.iter().filter(|w| lower.contains(*w)).count();
    let t_score: usize = neg_words.iter().filter(|w| lower.contains(*w)).count();
    let o_score: usize = neu_words.iter().filter(|w| lower.contains(*w)).count();

    let total = (p_score + t_score + o_score).max(1) as f64;

    if p_score > t_score && p_score > o_score {
        (1, (p_score as f64 / total).min(0.85))
    } else if t_score > p_score && t_score > o_score {
        (-1, (t_score as f64 / total).min(0.85))
    } else {
        (0, (o_score as f64 / total).max(0.5).min(0.75))
    }
}

// â”€â”€ 3ì§„ ë‹¤ìˆ˜ê²° â”€â”€

pub fn trit_consensus(votes: &[i8]) -> (i8, f64) {
    if votes.is_empty() { return (0, 0.0); }
    let p = votes.iter().filter(|&&v| v > 0).count();
    let t = votes.iter().filter(|&&v| v < 0).count();
    let o = votes.iter().filter(|&&v| v == 0).count();
    let total = votes.len() as f64;

    let consensus = if p > t && p > o { 1 }
        else if t > p && t > o { -1 }
        else if p == t && p > 0 { 0 }  // ë™ë¥ ì´ë©´ ë³´ë¥˜
        else { 0 };

    let majority = p.max(t).max(o);
    let confidence = majority as f64 / total;

    (consensus, confidence)
}

// â”€â”€ CTP í—¤ë” ìƒì„± â”€â”€

pub fn build_ctp_header(consensus: i8, responses: &[AIResponse]) -> [i8; 9] {
    let mut header = [0i8; 9];

    // [0] state: ìµœì¢… í•©ì˜
    header[0] = consensus;

    // [1] permission: ëª¨ë“  ëª¨ë¸ ì‘ë‹µ ì„±ê³µ ì—¬ë¶€
    header[1] = if responses.iter().all(|r| r.success) { 1 } else { -1 };

    // [2] consensus: ë§Œì¥ì¼ì¹˜ ì—¬ë¶€
    let all_same = responses.iter().all(|r| r.trit == consensus);
    header[2] = if all_same { 1 } else { 0 };

    // [3] transaction: ì‘ë‹µ ìˆ˜ ì¶©ì¡±
    header[3] = if responses.len() >= 2 { 1 } else { 0 };

    // [4] routing: ì§€ì—°ì‹œê°„ (300ms ì´í•˜ë©´ P)
    let avg_latency = if responses.is_empty() { 0 } else {
        responses.iter().map(|r| r.latency_ms as u64).sum::<u64>() / responses.len() as u64
    };
    header[4] = if avg_latency < 300 { 1 } else if avg_latency < 1000 { 0 } else { -1 };

    // [5-8] ê°œë³„ ëª¨ë¸ ê²°ê³¼
    for (i, resp) in responses.iter().take(4).enumerate() {
        header[5 + i] = resp.trit;
    }

    header
}

// â”€â”€ ë¡œì»¬ í•©ì˜ ì—”ì§„ â”€â”€

pub struct LocalConsensusEngine {
    pub endpoints: Vec<AIEndpoint>,
    pub results: Vec<ConsensusResult>,
    pub request_counter: u64,
    pub total_consensus_calls: u64,
    pub agreement_rate: f64,
}

impl LocalConsensusEngine {
    pub fn new() -> Self {
        Self {
            endpoints: Vec::new(),
            results: Vec::new(),
            request_counter: 0,
            total_consensus_calls: 0,
            agreement_rate: 0.0,
        }
    }

    /// OpenClaw ê¸°ë³¸ ì„¤ì • â€” 3ê°œ ë¡œì»¬ AI
    pub fn openclaw_default() -> Self {
        let mut engine = Self::new();
        engine.add_endpoint(AIEndpoint::new("Claude", "127.0.0.1", 18789, ModelType::Claude));
        engine.add_endpoint(AIEndpoint::new("Gemini", "127.0.0.1", 18790, ModelType::Gemini));
        engine.add_endpoint(AIEndpoint::new("Sonnet", "127.0.0.1", 18791, ModelType::Sonnet));
        engine
    }

    pub fn add_endpoint(&mut self, endpoint: AIEndpoint) {
        self.endpoints.push(endpoint);
    }

    pub fn active_endpoints(&self) -> Vec<&AIEndpoint> {
        self.endpoints.iter()
            .filter(|e| e.status == EndpointStatus::Online)
            .collect()
    }

    /// ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ í•©ì˜ (ì‹¤ì œ HTTP ì—†ì´)
    pub fn simulate_consensus(&mut self, prompt: &str) -> ConsensusResult {
        self.request_counter += 1;
        let req = ConsensusRequest::new(self.request_counter, prompt);
        let start = Instant::now();

        let mut responses = Vec::new();

        for (i, endpoint) in self.endpoints.iter_mut().enumerate() {
            let sim_start = Instant::now();

            // ëª¨ë¸ë³„ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ ìƒì„±
            let (text, base_trit) = simulate_model_response(prompt, &endpoint.model_type, i);
            let (trit, confidence) = classify_trit(&text);
            let latency = sim_start.elapsed().as_millis() as u32 + 50 + (i as u32 * 30);

            endpoint.total_calls += 1;
            endpoint.latency_ms = latency;

            responses.push(AIResponse {
                endpoint_name: endpoint.name.clone(),
                model_type: endpoint.model_type.clone(),
                text,
                trit,
                confidence,
                latency_ms: latency,
                success: true,
                error: None,
                timestamp: now_ms(),
            });
        }

        let votes: Vec<i8> = responses.iter().map(|r| r.trit).collect();
        let (final_trit, consensus_confidence) = trit_consensus(&votes);
        let unanimous = votes.iter().all(|&v| v == final_trit);
        let ctp_header = build_ctp_header(final_trit, &responses);
        let total_latency = start.elapsed().as_millis() as u32;

        self.total_consensus_calls += 1;
        if unanimous {
            self.agreement_rate = (self.agreement_rate * (self.total_consensus_calls - 1) as f64 + 1.0)
                / self.total_consensus_calls as f64;
        } else {
            self.agreement_rate = self.agreement_rate * (self.total_consensus_calls - 1) as f64
                / self.total_consensus_calls as f64;
        }

        let result = ConsensusResult {
            request_id: req.id,
            prompt: prompt.to_string(),
            responses,
            final_trit,
            confidence: consensus_confidence,
            unanimous,
            ctp_header,
            total_latency_ms: total_latency,
            timestamp: now_ms(),
        };

        self.results.push(result.clone());
        result
    }

    /// HTTP ìš”ì²­ ìŠ¤í™ ìƒì„± (ì‹¤ì œ ì—°ê²°ìš©)
    pub fn generate_http_spec(&self, prompt: &str) -> Vec<String> {
        let mut specs = Vec::new();
        for ep in &self.endpoints {
            let spec = format!(
r#"curl -X POST {}/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{{
    "model": "{}",
    "messages": [
      {{"role": "system", "content": "ë‹¹ì‹ ì€ 3ì§„ íŒë‹¨ AIì…ë‹ˆë‹¤. [íŒì •: P/O/T] í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”."}},
      {{"role": "user", "content": "{}"}}
    ],
    "max_tokens": 1000
  }}'"#,
                ep.url(), ep.model_type, prompt.replace('"', "\\\"")
            );
            specs.push(spec);
        }
        specs
    }

    /// ì—”ì§„ ìƒíƒœ ìš”ì•½
    pub fn summary(&self) -> String {
        let mut lines = Vec::new();
        lines.push("â•â•â• Crowny Local Consensus Engine â•â•â•".to_string());
        lines.push(format!("  ì—”ë“œí¬ì¸íŠ¸: {}", self.endpoints.len()));
        for ep in &self.endpoints {
            lines.push(format!("    {} {} ({}) â€” {} | calls:{} | {}ms",
                match ep.status { EndpointStatus::Online => "â—", _ => "â—‹" },
                ep.name, ep.url(), ep.status, ep.total_calls, ep.latency_ms));
        }
        lines.push(format!("  ì´ í•©ì˜: {} | ë§Œì¥ì¼ì¹˜ìœ¨: {:.0}%",
            self.total_consensus_calls, self.agreement_rate * 100.0));
        if let Some(last) = self.results.last() {
            lines.push(format!("  ìµœê·¼: {}", last));
        }
        lines.join("\n")
    }
}

// â”€â”€ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ ìƒì„± â”€â”€

fn simulate_model_response(prompt: &str, model: &ModelType, seed: usize) -> (String, i8) {
    let lower = prompt.to_lowercase();

    // í”„ë¡¬í”„íŠ¸ì—ì„œ ê¸ì •/ë¶€ì • íŒíŠ¸ ì¶”ì¶œ
    let has_risk = lower.contains("ìœ„í—˜") || lower.contains("ì‹¤íŒ¨") || lower.contains("ë¶ˆê°€");
    let has_positive = lower.contains("ì¶”ì²œ") || lower.contains("ì„±ê³µ") || lower.contains("ê°€ëŠ¥");
    let has_invest = lower.contains("íˆ¬ì") || lower.contains("ìŠ¤íƒ€íŠ¸ì—…") || lower.contains("ì£¼ì‹");
    let has_medical = lower.contains("ìˆ˜ìˆ ") || lower.contains("í™˜ì") || lower.contains("ì˜ë£Œ");
    let has_tech = lower.contains("ê¸°ìˆ ") || lower.contains("ê°œë°œ") || lower.contains("ì½”ë”©");

    match model {
        ModelType::Claude => {
            if has_risk {
                (format!("[Claude ë¶„ì„] \"{}\" â€” ë¦¬ìŠ¤í¬ ìš”ì†Œê°€ ê°ì§€ë©ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•˜ì§€ë§Œ, ì ì ˆí•œ ì™„í™” ì „ëµì´ ìˆë‹¤ë©´ ì¡°ê±´ë¶€ ì§„í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. [íŒì •: O]", truncate(prompt, 30)), 0)
            } else if has_invest {
                (format!("[Claude ë¶„ì„] \"{}\" â€” ì¬ë¬´ ë°ì´í„°ì™€ ì‹œì¥ ë™í–¥ì„ êµì°¨ ê²€ì¦í•œ ê²°ê³¼, ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ê¸°ëŒ€ ìˆ˜ìµì´ ì–‘í˜¸í•©ë‹ˆë‹¤. ë¶„ì‚° íˆ¬ì ì›ì¹™ í•˜ì— ì§„í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤. [íŒì •: P]", truncate(prompt, 30)), 1)
            } else if has_medical {
                (format!("[Claude ë¶„ì„] \"{}\" â€” ì˜ë£Œ íŒë‹¨ì€ ë‹¤ë©´ì  í‰ê°€ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë¡œëŠ” í™•ì • íŒë‹¨ì´ ì–´ë µìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ ì¶”ê°€ ì†Œê²¬ì„ ê¶Œí•©ë‹ˆë‹¤. [íŒì •: O]", truncate(prompt, 30)), 0)
            } else {
                (format!("[Claude ë¶„ì„] \"{}\" â€” ë‹¤ê°ë„ ë¶„ì„ ê²°ê³¼, ì „ë°˜ì ìœ¼ë¡œ ê¸ì •ì  ìš”ì†Œê°€ ìš°ì„¸í•©ë‹ˆë‹¤. ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤. [íŒì •: P]", truncate(prompt, 30)), 1)
            }
        }
        ModelType::Gemini => {
            if has_risk {
                (format!("[Gemini ë¶„ì„] \"{}\" â€” ìœ„í—˜ ì‹ í˜¸ê°€ ë³µìˆ˜ ê°ì§€ë©ë‹ˆë‹¤. í˜„ ì‹œì ì—ì„œëŠ” ì§„í–‰ì„ ë³´ë¥˜í•˜ê³  ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì„ ê¶Œí•©ë‹ˆë‹¤. [íŒì •: T]", truncate(prompt, 30)), -1)
            } else if has_invest {
                (format!("[Gemini ë¶„ì„] \"{}\" â€” ì‹œì¥ ë¶„ì„ê³¼ ê²½ìŸ êµ¬ë„ë¥¼ ê³ ë ¤í•  ë•Œ, íƒ€ì´ë°ì´ ì ì ˆí•©ë‹ˆë‹¤. ë‹¤ë§Œ í¬ì§€ì…˜ ì‚¬ì´ì§•ì— ì£¼ì˜í•˜ì„¸ìš”. [íŒì •: P]", truncate(prompt, 30)), 1)
            } else if has_medical {
                (format!("[Gemini ë¶„ì„] \"{}\" â€” í™˜ì ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ê²°ê³¼, ìˆ˜ìˆ  ì„±ê³µ í™•ë¥ ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤. ì¡°ê±´ë¶€ ì¶”ì²œí•©ë‹ˆë‹¤. [íŒì •: P]", truncate(prompt, 30)), 1)
            } else {
                (format!("[Gemini ë¶„ì„] \"{}\" â€” êµì°¨ ê²€ì¦ ê²°ê³¼ ëŒ€ë¶€ë¶„ì˜ ì§€í‘œê°€ ê¸ì •ì ì…ë‹ˆë‹¤. ì§„í–‰ì„ ì§€ì§€í•©ë‹ˆë‹¤. [íŒì •: P]", truncate(prompt, 30)), 1)
            }
        }
        ModelType::Sonnet => {
            if has_risk {
                (format!("[Sonnet ë¶„ì„] \"{}\" â€” êµ¬ì¡°ì  ë¦¬ìŠ¤í¬ê°€ ì‹ë³„ë©ë‹ˆë‹¤. ë³´ìˆ˜ì  ì ‘ê·¼ì„ ê°•ë ¥ ê¶Œì¥í•©ë‹ˆë‹¤. [íŒì •: T]", truncate(prompt, 30)), -1)
            } else if has_invest {
                (format!("[Sonnet ë¶„ì„] \"{}\" â€” í€ë”ë©˜í„¸ ë¶„ì„ ê²°ê³¼ ì ì¬ë ¥ì´ ìˆìœ¼ë‚˜, ë‹¨ê¸° ë³€ë™ì„±ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤. [íŒì •: O]", truncate(prompt, 30)), 0)
            } else if has_medical {
                (format!("[Sonnet ë¶„ì„] \"{}\" â€” ì˜ë£Œ ìœ¤ë¦¬ì™€ í™˜ì ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•  ë•Œ, ë¹„ì¹¨ìŠµì  ëŒ€ì•ˆì„ ë¨¼ì € ê²€í† í•˜ì„¸ìš”. [íŒì •: O]", truncate(prompt, 30)), 0)
            } else if has_tech {
                (format!("[Sonnet ë¶„ì„] \"{}\" â€” ê¸°ìˆ ì  íƒ€ë‹¹ì„±ì´ í™•ì¸ë©ë‹ˆë‹¤. ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì„ ê¶Œì¥í•©ë‹ˆë‹¤. [íŒì •: P]", truncate(prompt, 30)), 1)
            } else {
                (format!("[Sonnet ë¶„ì„] \"{}\" â€” ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ë©´ ì‹¤í–‰ ê°€ëŠ¥í•œ ë²”ìœ„ì…ë‹ˆë‹¤. ì§„í–‰ì„ ê¶Œí•©ë‹ˆë‹¤. [íŒì •: P]", truncate(prompt, 30)), 1)
            }
        }
        ModelType::Custom(name) => {
            (format!("[{} ë¶„ì„] \"{}\" â€” ì¼ë°˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. [íŒì •: O]", name, truncate(prompt, 30)), 0)
        }
    }
}

fn truncate(s: &str, max_chars: usize) -> String {
    let chars: Vec<char> = s.chars().collect();
    if chars.len() <= max_chars {
        s.to_string()
    } else {
        let truncated: String = chars[..max_chars].iter().collect();
        format!("{}...", truncated)
    }
}

fn now_ms() -> u64 {
    SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_millis() as u64
}

// â•â•â• ë°ëª¨ â•â•â•

pub fn demo_local_consensus() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  Crowny Local Consensus Engine            â•‘");
    println!("â•‘  ì‹¤ì œ ë¡œì»¬ 3ì§„ í•©ì˜ â€” OpenClaw ë“€ì–¼ ë¸Œë ˆì¸  â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    // 1. ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
    println!("â”â”â” 1. OpenClaw ì—”ë“œí¬ì¸íŠ¸ â”â”â”");
    let mut engine = LocalConsensusEngine::openclaw_default();
    for ep in &engine.endpoints {
        println!("  {} {} ({}) â€” {}", "â—", ep.name, ep.url(), ep.model_type);
    }
    println!();

    // 2. ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ í•©ì˜
    let scenarios = vec![
        ("ì´ ìŠ¤íƒ€íŠ¸ì—…ì— íˆ¬ìí•´ì•¼ í• ê¹Œ?", "íˆ¬ì"),
        ("í™˜ìì—ê²Œ ìˆ˜ìˆ ì„ ê¶Œí•´ì•¼ í• ê¹Œ?", "ì˜ë£Œ"),
        ("ì´ ê¸°ìˆ  ìŠ¤íƒìœ¼ë¡œ ê°œë°œì„ ì‹œì‘í•´ë„ ë ê¹Œ?", "ê¸°ìˆ "),
        ("ìœ„í—˜í•œ ì‹œì¥ì— ì§„ì…í•´ì•¼ í• ê¹Œ?", "ìœ„í—˜"),
        ("3ì§„ë²•ì´ 2ì§„ë²•ë³´ë‹¤ íš¨ìœ¨ì ì¸ê°€?", "ê¸°ìˆ "),
    ];

    println!("â”â”â” 2. 3ì§„ í•©ì˜ ì‹œë‚˜ë¦¬ì˜¤ â”â”â”");
    for (prompt, category) in &scenarios {
        println!("  ğŸ“‹ [{}] \"{}\"", category, prompt);
        let result = engine.simulate_consensus(prompt);

        for resp in &result.responses {
            println!("    {}", resp);
        }
        println!("    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
        println!("    ğŸ› {}", result);
        println!();
    }

    // 3. HTTP ìŠ¤í™ (ì‹¤ì œ ì—°ê²°ìš©)
    println!("â”â”â” 3. ì‹¤ì œ HTTP ì—°ê²° ìŠ¤í™ â”â”â”");
    let specs = engine.generate_http_spec("ì´ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•´ì•¼ í• ê¹Œ?");
    for (i, spec) in specs.iter().enumerate() {
        println!("  [{}/{}] {}", i + 1, specs.len(), &spec[..spec.find('\n').unwrap_or(spec.len())]);
    }
    println!("  (ì „ì²´ curl ëª…ë ¹ì€ --verbose ì˜µì…˜ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥)");
    println!();

    // 4. í†µê³„
    println!("â”â”â” 4. ì—”ì§„ í†µê³„ â”â”â”");
    println!("{}", engine.summary());
    println!();

    // 5. í•©ì˜ ì´ë ¥
    println!("â”â”â” 5. í•©ì˜ ì´ë ¥ â”â”â”");
    for result in &engine.results {
        let trit = match result.final_trit { 1 => "P", -1 => "T", _ => "O" };
        let ctp = result.ctp_string();
        let prompt_short = truncate(&result.prompt, 25);
        println!("  #{} [{}] {} â€” CTP:{} | {:.0}% | {}ms",
            result.request_id, trit, prompt_short, ctp, result.confidence * 100.0, result.total_latency_ms);
    }
    println!();

    println!("âœ“ ë¡œì»¬ í•©ì˜ ë°ëª¨ ì™„ë£Œ â€” {} ì‹œë‚˜ë¦¬ì˜¤, {} ì—”ë“œí¬ì¸íŠ¸",
        engine.results.len(), engine.endpoints.len());
}

// â•â•â• í…ŒìŠ¤íŠ¸ â•â•â•

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_endpoint_creation() {
        let ep = AIEndpoint::new("Claude", "127.0.0.1", 18789, ModelType::Claude);
        assert_eq!(ep.url(), "http://127.0.0.1:18789");
        assert_eq!(ep.port, 18789);
    }

    #[test]
    fn test_openclaw_default() {
        let engine = LocalConsensusEngine::openclaw_default();
        assert_eq!(engine.endpoints.len(), 3);
        assert_eq!(engine.endpoints[0].port, 18789);
        assert_eq!(engine.endpoints[1].port, 18790);
        assert_eq!(engine.endpoints[2].port, 18791);
    }

    #[test]
    fn test_classify_trit_explicit() {
        let (trit, conf) = classify_trit("ë¶„ì„ ê²°ê³¼ [íŒì •: P]");
        assert_eq!(trit, 1);
        assert!(conf > 0.9);

        let (trit, _) = classify_trit("[íŒì •: T] ê±°ë¶€í•©ë‹ˆë‹¤");
        assert_eq!(trit, -1);

        let (trit, _) = classify_trit("[íŒì •: O] ë³´ë¥˜");
        assert_eq!(trit, 0);
    }

    #[test]
    fn test_classify_trit_keywords() {
        let (trit, _) = classify_trit("ì´ ë°©ì•ˆì€ ì¶”ì²œí•˜ê³  ìŠ¹ì¸í•©ë‹ˆë‹¤");
        assert_eq!(trit, 1);

        let (trit, _) = classify_trit("ìœ„í—˜í•˜ê³  ë¶ˆê°€ëŠ¥í•œ ê±°ë¶€ ëŒ€ìƒì…ë‹ˆë‹¤");
        assert_eq!(trit, -1);
    }

    #[test]
    fn test_trit_consensus() {
        assert_eq!(trit_consensus(&[1, 1, -1]).0, 1);    // 2P vs 1T â†’ P
        assert_eq!(trit_consensus(&[-1, -1, 1]).0, -1);   // 2T vs 1P â†’ T
        assert_eq!(trit_consensus(&[1, -1, 0]).0, 0);     // ë™ë¥  â†’ O
        assert_eq!(trit_consensus(&[1, 1, 1]).0, 1);      // ë§Œì¥ì¼ì¹˜ P
    }

    #[test]
    fn test_consensus_confidence() {
        let (_, conf) = trit_consensus(&[1, 1, 1]);
        assert!((conf - 1.0).abs() < 0.01); // 100%

        let (_, conf) = trit_consensus(&[1, 1, -1]);
        assert!((conf - 0.666).abs() < 0.01); // ~66%
    }

    #[test]
    fn test_ctp_header() {
        let responses = vec![
            AIResponse { endpoint_name: "a".into(), model_type: ModelType::Claude, text: "".into(), trit: 1, confidence: 0.9, latency_ms: 100, success: true, error: None, timestamp: 0 },
            AIResponse { endpoint_name: "b".into(), model_type: ModelType::Gemini, text: "".into(), trit: 1, confidence: 0.8, latency_ms: 200, success: true, error: None, timestamp: 0 },
            AIResponse { endpoint_name: "c".into(), model_type: ModelType::Sonnet, text: "".into(), trit: -1, confidence: 0.7, latency_ms: 150, success: true, error: None, timestamp: 0 },
        ];
        let header = build_ctp_header(1, &responses);
        assert_eq!(header[0], 1);  // state: P
        assert_eq!(header[1], 1);  // permission: all success
        assert_eq!(header[2], 0);  // consensus: not unanimous
        assert_eq!(header[5], 1);  // model 0: P
        assert_eq!(header[7], -1); // model 2: T
    }

    #[test]
    fn test_simulate_consensus() {
        let mut engine = LocalConsensusEngine::openclaw_default();
        let result = engine.simulate_consensus("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì…ë‹ˆë‹¤");
        assert_eq!(result.responses.len(), 3);
        assert!(result.confidence > 0.0);
    }

    #[test]
    fn test_http_spec_generation() {
        let engine = LocalConsensusEngine::openclaw_default();
        let specs = engine.generate_http_spec("í…ŒìŠ¤íŠ¸");
        assert_eq!(specs.len(), 3);
        assert!(specs[0].contains("18789"));
        assert!(specs[1].contains("18790"));
        assert!(specs[2].contains("18791"));
    }

    #[test]
    fn test_engine_stats() {
        let mut engine = LocalConsensusEngine::openclaw_default();
        engine.simulate_consensus("q1");
        engine.simulate_consensus("q2");
        assert_eq!(engine.total_consensus_calls, 2);
        assert_eq!(engine.results.len(), 2);
    }
}
